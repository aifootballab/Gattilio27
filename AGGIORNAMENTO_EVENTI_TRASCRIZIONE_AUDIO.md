# ðŸŽ¤ Aggiornamento Eventi Trascrizione Audio
## Aggiunta gestione eventi audio Realtime API

**Data**: 2025-01-14  
**Status**: ðŸ”´ **DA IMPLEMENTARE**

---

## ðŸ“š DOCUMENTAZIONE OPENAI

Secondo la documentazione ufficiale OpenAI Realtime API, ci sono eventi specifici per la trascrizione audio:

### **Eventi Input Audio (Utente parla)**:

1. **`input_audio_transcription.completed`**
   - Emesso quando l'audio dell'utente viene trascritto
   - Contiene il testo completo trascritto
   - Utile per mostrare all'utente cosa ha detto

2. **`input_audio_transcription.failed`**
   - Emesso se la trascrizione fallisce
   - Contiene dettagli errore

### **Eventi Response Audio (GPT parla)**:

1. **`response.audio_transcript.done`**
   - Emesso quando l'audio della risposta viene trascritto (se abilitato)
   - Utile per mostrare trascrizione della risposta vocale

---

## âŒ PROBLEMA ATTUALE

**Eventi gestiti**:
- âœ… `session.created`
- âœ… `response.text.delta`
- âœ… `response.text.done`
- âœ… `response.function_call`
- âœ… `error`

**Eventi mancanti**:
- âŒ `input_audio_transcription.completed` - Trascrizione audio utente
- âŒ `input_audio_transcription.failed` - Errore trascrizione
- âŒ `response.audio_transcript.done` - Trascrizione risposta (opzionale)

---

## âœ… SOLUZIONE

### **1. Aggiungere Callback per Trascrizione**

```javascript
// Nuovo callback per trascrizione audio utente
onAudioTranscription: ((text: string) => void) | null = null
```

### **2. Gestire Eventi nel handleMessage**

```javascript
case 'input_audio_transcription.completed':
  // Trascrizione audio utente completata
  if (this.onAudioTranscription && event?.text) {
    this.onAudioTranscription(event.text)
  }
  break

case 'input_audio_transcription.failed':
  // Errore trascrizione
  if (this.onError) {
    this.onError(new Error(`Audio transcription failed: ${event.error}`))
  }
  break

case 'response.audio_transcript.done':
  // Trascrizione risposta audio (opzionale)
  console.log('ðŸŽ¤ Response audio transcribed:', event.text)
  break
```

### **3. Mostrare Trascrizione in UI**

- Mostrare trascrizione in tempo reale mentre utente parla
- Mostrare errore se trascrizione fallisce
- Opzionale: mostrare trascrizione risposta audio

---

## ðŸŽ¯ BENEFICI

1. **Feedback Utente**:
   - Utente vede cosa ha detto mentre parla
   - Migliore UX (come ChatGPT voice)

2. **Debug**:
   - Possiamo vedere se audio viene trascritto correttamente
   - Identificare problemi di qualitÃ  audio

3. **AccessibilitÃ **:
   - Utenti possono vedere trascrizione se preferiscono leggere

---

## ðŸ“‹ IMPLEMENTAZIONE

### **File da Modificare**:

1. **`services/realtimeCoachingServiceV2.js`**
   - Aggiungere callback `onAudioTranscription`
   - Gestire eventi trascrizione in `handleMessage()`

2. **`components/coaching/VoiceCoachingPanel.jsx`**
   - Mostrare trascrizione in UI
   - Aggiornare messaggio utente con trascrizione

---

**Status**: ðŸ”´ **DA IMPLEMENTARE** - Aggiungere gestione eventi trascrizione
